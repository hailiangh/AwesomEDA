## AI



- Customized Retrieval Augmented Generation and Benchmarking for EDA Tool Documentation QA
- Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures


## Design Automation
- An Agile Framework for Efficient LLM Accelerator Development and Model Inference
- Spiking Transformer Hardware Accelerators in 3D Integration
- Dataflow Accelerator Architecture for Autonomous Machine Computing
- TSB: Tiny Shared Block for Efficient DNN Deployment on NVCIM Accelerators
- MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers
- RACI: A Resource-Aware Cooperative Inference Framework on Heterogeneous Edge Devices
- Foveated HDR: Efficient HDR Content Generation on Edge Devices Leveraging User's Visual Attention
- ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters
- EasyPart: An Effective and Comprehensive Hypergraph Partitioner for FPGA-based Emulation
- AdaPI: Facilitating DNN Model Adaptivity for Efficient Private Inference in Edge Computing
- EPipe: Pipeline Inference Framework with High-quality Offline Parallelism Planning for Heterogeneous Edge Devices
- Residual-INR: Communication Efficient On-Device Learning Using Implicit Neural Representation
- DoS-FPGA: Denial of Service on Cloud FPGAs via Coordinated Power Hammering
- HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline
- Co-Designing NVM-based Systems for Machine Learning and In-memory Search Applications
- Non-volatile Memory Technologies for Edge AI
- Challenges and opportunities in accelerating large-scale search problems using NVM-based in-memory computing
- Memory-Centric Deployment of Machine Learning Models
- Is Vanilla Bayesian Optimization Enough for High-Dimensional Architecture Design Optimization?
- TransLib: An Extensible Graph-Aware Library Framework for Automated Generation of Transformer Operators on FPGA
- Hierarchical Power Co-Optimization and Management for LLM Chiplet Designs
- Partial Differential Equation Acceleration by Exploiting Value Similarity
- A Sparsity-Aware Autonomous Path Planning Accelerator with Algorithm-Architecture Co-Design
- Edge-BiT: Software-Hardware Co-design for Optimizing Binarized Transformer Networks Inference on Edge FPGA
- Co-Designing Binarized Transformer and Hardware Accelerator for Efficient End-to-End Edge Deployment
- An Agile Framework for Efficient LLM Accelerator Development and Model Inference
- ALISE: Accelerating Large Language Model Serving with Speculative Scheduling
- ChatOPU: An FPGA-based Overlay Processor for Large Language Models with Unstructured Sparsity
- LACO: A Latency-Constraint Offline Neural Network Scheduler towards Reliable Self-Driving Perception
- CoCoA: Algorithm-Hardware Co-Design for Large-Scale GNN Training using Compressed Graph
- FLOP: A Flexible Memory-Optimized Processor for Parallel Graph Mining on FPGA
- TP-DCIM: Transposable Digital SRAM CIM Architecture for Energy-Efficient and High Throughput Transformer Acceleration
- FSMM: An Efficient Matrix Multiplication Accelerator Supporting Flexible Sparsity


 

## Placement
- **Fusion of Global Placement and Gate Sizing with Differentiable Optimization**
- Modern Fixed-Outline Floorplanning with Rectilinear Soft Modules
- JigsawPlanner: Jigsaw-like Floorplanner for Eliminating Whitespace and Overlap among Complex Rectilinear Modules
- SysMix: Mixed-Size Placement for Systolic-Array-Based Hierarchical Designs
- An Effective Analytical Placement Approach to Handle Fence Region Constraint
- Hybrid Modeling and Weighting for Timing-driven Placement with Efficient Calibration
- A Physical and Timing Aware Placement Optimization Framework Based on Graph Neural Network
- LAG-Sizer: A Novel Gate Sizer Based on Leak Generative Adversarial Network with Feature Fusion
- RankTuner: When Design Tool Parameter Tuning Meets Preference Bayesian Optimization
- The Power of Graph Signal Processing for Chip Placement Acceleration
- Joint Placement Optimization for Hierarchical Analog/Mixed-Signal Circuits
- OCTS: An Optical Clock Tree Synthesis Methodology for 2.5D Systems

## Timing
- HeteroExcept: A CPU-GPU Heterogeneous Algorithm to Accelerate Exception-aware Static Timing Analysis
- CircuitSeer: RTL Post-PnR Delay Prediction via Coupling Functional and Structural Representation
- Explainable and Layout-Aware Timing Prediction


## Algorithms
- Neuromorphic Computing for Graph Analytics
- **GAT-Steiner: Rectilinear Steiner Minimal Tree Prediction Using GNNs**

## HLS
- **MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning**
- A Machine Learning Guided Cut Choices for ASIC Technology Mapping
- Physically Aware Synthesis Revisited: Guiding Technology Mapping with Primitive Logic Gate Placement
- RapidIR: A Practical Infrastructure for FPGA High-Level Physical Synthesis
- Extending High-Level Synthesis with AI/ML Methods
- Are LLMs Any Good for High-Level Synthesis?
- High(er) Level Synthesis: Can HLS Tools Benefit from LLMs?

## Benchmarks
- Generative Methods in EDA: Innovations in Dataset Generation and EDA Tool Assistants
- EDALearn: A Comprehensive RTL-to-Signoff EDA Benchmark for Democratized and Reproducible ML for EDA Research
- AnalogGym: An Open and Practical Testing Suite for Analog Circuit Synthesis
- OpenLLM-RTL: Open Dataset and Benchmark for LLM-Aided Design RTL Generation
- Customized Retrieval Augmented Generation and Benchmarking for EDA Tool Documentation QA
- Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation
- FloorSet - a VLSI Floorplanning Dataset with Design Constraints of Real-World SOCs.

## LLM RTL
- RTLRewriter: Methodologies for Large Models aided RTL Code Optimization
- OriGen: Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection
- MEIC: Re-thinking RTL Debug Automation using LLMs

